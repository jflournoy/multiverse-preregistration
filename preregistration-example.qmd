---
title: "Preregistration Example"
number-sections: true
bibliography: multiverse.bib
---


# Research question (construct-level) {#sec-research-question}

How is pubertal development related to neural activation during self-referential processing? 

(_Note: added after considering certain Type U decisions_) Does the association between puberty and self-referential processing vary depending on the ROI and contrast; and which measure of puberty provides the best-fitting model?

# Decisions

## Covariates (other constucts)

N/A

## Causal model(s)

N/A

## Measurements of constructs 

### Self-referential processing contrast

The task consisted of self-referential processing of

1. prosocial
2. anti-social
3. and withdrawn

trait descriptors, contrasted against these same adjectives in a non-social setting.

### fMRI Data

BOLD contrast estimates from a self-evaluation task while undergoing functional neuroimaging [@barendse2020a].

Mean contrast estimates from each participant at each wave were extracted from

1. pgACC
2. sgACC
3. vmPFC
4. PCC

### Pubertal development

1. Pubertal Development Scale
2. Tanner Stage Line Drawings
3, Salivary DHEA
4. Salivary testosterone
5. Salivary estradiol

## Processing of measurements

### ROI Atlas

We extracted data from ROIs defined from parcels using 

1. HCP atlas
2. Schaefer 400 atlas

### Motion regressors

We included a motion "trash" regressor in the first-level modeling defined by 

1. Framewise displacement  > .75mm
2. Artifact prediction from the auto-motion-fmriprep classifie [@cosme2018]

### Noramalization template

We normalized (i.e., registered) scans to 

1. Pediatric template
2. Adult template

### Smoothing Kernel

We smoothed by

1. 6mm
2. 4mm

## Sample composition

### Motion exclusions

We kept particpants who had

1. Any amount of trash-regressor trials
2. &gt;80% non-trash-regressor trials
3. &gt;90% non-trash-regressor trials

# Decision types

## Type E

1. Normalization template
2. Smoothing kernel

## Type N

1. Exclusion criteria

Although exclusion criteria change the sample size, which changes power and precision, not excluding bad data may negatively impact precision or lead to bias, so we choose to examine these choice options.

## Type U

1. Parcellation atlas
2. Motion (trash) regressors

## Statistical comparison of Type U decisions {#sec-type-u-comps}

We started out identifying choice of region of interest in the social brain as a potential Type U decision. Does it matter whether we use data from ventro-medial prefrontal cortext (vmPFC) or posterior cingulate cortex (PCC)? Instead of examining several different multiverses for each ROI to examine the robustness of the effect size or significance of our association of interest, we could test this question in a model-based way. We also decided that choice of pubertal measure and self-referential processing contrast could be examined via model comparison [but see @byrne2019 regarding the measurement structure of puberty]. 

Therefore we decided to additionally examine the question: does the association between puberty and self-referential processing vary depending on the ROI and contrast; and which measure of puberty provides the best-fitting model?

# Organizing the multiverse

We will define a number of multiverses using the combination of parcellation atlas (U; 2 options), motion regressor (U, 3 options) and exclusion criteria (N, 3 options), for a total of 18 (@fig-typeun). Within each multiverse, analytic specifications comprise combinations of normalization template (2 options) and smoothing kernel (2 options) for a total of 4 (@fig-typee).

```{r}
#| fig-width: 6.5
#| fig-height: 4
#| fig-cap: "Possible decision paths through Type U and Type N decisions"
#| label: fig-typeun
#| warning: false
#| message: false
#| echo: false


library(ggraph)
library(igraph)
library(tidyverse)
m0 <- tibble(from = 'Start', to = c('HCP', 'Schaefer'))
m1 <- tibble(from = rep(c('HCP', 'Schaefer'), each = 2),
             to = rep(c('Classifier', 'FD'), 2))
m2 <- tibble(from = rep(c('Classifier', 'FD'), each = 3),
             to = rep(c('Ex >10%', 'Ex >20%', 'Ex None'), 2))
m_edges <- do.call(rbind, list(m0, m1, m2))
m_graph <- graph_from_data_frame(m_edges)

m_paths <- all_simple_paths(m_graph, from = 'Start', to = c('Ex >10%', 'Ex >20%', 'Ex None'))

n_m_paths <- length(m_paths)
m_path_colors <- viridis::cividis(n_m_paths)

m_g <- set_vertex_attr(make_empty_graph(directed = TRUE, n = length(V(m_graph)$name)),
                       "name", value = V(m_graph)$name)

m_paths_path <- lapply(1:n_m_paths, function(i){
  path(m_paths[[i]], color = m_path_colors[[i]])
})

m_g_paths <- delete_vertices(Reduce(igraph:::`+.igraph`, c(list(m_g), m_paths_path)), 'Start')

V(m_g_paths)$group <- unlist(mapply(rep, c('Atlas', 'Motion Regressor', 'Motion Exclusions'), each = c(2, 2, 3)))

ggraph(m_g_paths,
       layout = 'igraph', algorithm = 'sugiyama') + 
  geom_edge_fan(arrow = arrow(type = 'closed', length = unit(.1, 'inches')),
                aes(fill = color)) +
  geom_node_point(size = 10,
                  aes(color = group)) +
  geom_node_text(aes(label = V(m_g_paths)$name), repel = FALSE, colour = 'black') +
  theme_void() + 
  scale_x_continuous(expand = expansion(mult = .1)) + 
  scale_y_continuous(expand = expansion(mult = .1))
```
```{r}
#| fig-width: 6.5
#| fig-height: 4
#| fig-cap: "Possible decision paths through Type E decisions"
#| label: fig-typee
#| warning: false
#| message: false
#| echo: false


s0 <- tibble(from = 'Start', to = c('Pediatric', 'Adult'))
s1 <- tibble(from = rep(c('Pediatric', 'Adult'), each = 2),
             to = rep(c('6mm', '4mm'), 2))
s_edges <- do.call(rbind, list(s0, s1))
s_graph <- graph_from_data_frame(s_edges)

s_paths <- all_simple_paths(s_graph, from = 'Start', to = c('6mm', '4mm'))

n_s_paths <- length(s_paths)
s_path_colors <- viridis::cividis(n_s_paths)

s_g <- set_vertex_attr(make_empty_graph(directed = TRUE, n = length(V(s_graph)$name)),
                       "name", value = V(s_graph)$name)

s_paths_path <- lapply(1:n_s_paths, function(i){
  path(s_paths[[i]], color = s_path_colors[[i]])
})

s_g_paths <- delete_vertices(Reduce(igraph:::`+.igraph`, c(list(s_g), s_paths_path)), 'Start')

V(s_g_paths)$group <- as.vector(unlist(mapply(rep, c('Template', 'Smoothing'), each = c(2, 2))))

ggraph(s_g_paths,
       layout = 'igraph', algorithm = 'sugiyama') + 
  geom_edge_fan(arrow = arrow(type = 'closed', length = unit(.1, 'inches')),
                aes(fill = color)) +
  geom_node_point(size = 13,
                  aes(color = group)) +
  geom_node_text(aes(label = name), repel = FALSE, colour = 'black') +
  theme_void() + 
  scale_x_continuous(expand = expansion(mult = .1)) + 
  scale_y_continuous(expand = expansion(mult = .1))

```

This organizational chunking, with a separate multiverse for each combination of decisions with incompatible options that itself contains multiple speficications that are combinations of decisions with reasonably interchangable options brings conceptual structure that aids interpretation and reduces combinatorial explosion. To get a sense of the complexity, the full picture of all possible analytic paths can be visualized as a single network diagram (@fig-alldec)


```{r}
#| fig-width: 6.5
#| fig-height: 4
#| fig-cap: "All possible decision paths"
#| latout-ncol: 2
#| fig-subcap:
#|   - "Colored by analysis"
#|   - "Colored by multiverse"
#| label: fig-alldec
#| warning: false
#| message: false
#| echo: false

library(ggnewscale)
m0 <- tibble(from = 'Start', to = c('HCP', 'Schaefer'))
m1 <- tibble(from = rep(c('HCP', 'Schaefer'), each = 2),
             to = rep(c('Classifier', 'FD'), 2))
m2 <- tibble(from = rep(c('Classifier', 'FD'), each = 3),
             to = rep(c('Ex >10%', 'Ex >20%', 'Ex None'), 2))
s0 <- tibble(from = rep(c('Ex >10%', 'Ex >20%', 'Ex None'), each = 2), to = rep(c('Pediatric', 'Adult'), 3))
s1 <- tibble(from = rep(c('Pediatric', 'Adult'), each = 2),
             to = rep(c('6mm', '4mm'), 2))
ms_edges <- do.call(rbind, list(m0, m1, m2, s0, s1))
ms_graph <- graph_from_data_frame(ms_edges)

ms_paths <- all_simple_paths(ms_graph, from = 'Start', to = c('6mm', '4mm'))

n_ms_paths <- length(ms_paths)
ms_path_colors <- viridis::cividis(n_ms_paths)

ms_g <- set_vertex_attr(make_empty_graph(directed = TRUE, n = length(V(ms_graph)$name)),
                       "name", value = V(ms_graph)$name)

ms_paths_path <- lapply(1:n_ms_paths, function(i){
  path(ms_paths[[i]], color = ms_path_colors[[i]])
})

ms_g_paths <- delete_vertices(Reduce(igraph:::`+.igraph`, c(list(ms_g), ms_paths_path)), 'Start')

#V(ms_g_paths)$name
V(ms_g_paths)$group <- unlist(mapply(rep, c('Multiverse', 'Specification'), each = c(7, 4)))

library(viridis)

ggraph(ms_g_paths,
       layout = 'igraph', algorithm = 'sugiyama') + 
  geom_edge_fan(aes(color = as.numeric(as.factor(color)))) +
  scale_edge_color_viridis(discrete = FALSE, option = 'cividis', alpha = .8,
                           name = 'Analysis Number') +
  geom_node_point(size = 10,
                  aes(color = group)) +
  scale_color_manual(breaks = c('Multiverse', 'Specification'), values = viridis::mako(2, begin = .5, end = .75),
                     labels = c('Separate\nmultiverse', 'Specification\nwithin multiverse'), name = '') + 
  geom_node_text(aes(label = V(ms_g_paths)$name), repel = FALSE, colour = 'black') +
  theme_void() + 
  scale_x_continuous(expand = expansion(mult = .1)) + 
  scale_y_continuous(expand = expansion(mult = .1))


library(ggnewscale)
m0 <- tibble(from = 'Start', to = c('HCP', 'Schaefer'))
m1 <- tibble(from = rep(c('HCP', 'Schaefer'), each = 2),
             to = rep(c('Classifier', 'FD'), 2))
m2 <- tibble(from = rep(c('Classifier', 'FD'), each = 3),
             to = rep(c('Ex >10%', 'Ex >20%', 'Ex None'), 2))
s0 <- tibble(from = rep(c('Ex >10%', 'Ex >20%', 'Ex None'), each = 2), to = rep(c('Pediatric', 'Adult'), 3))
s1 <- tibble(from = rep(c('Pediatric', 'Adult'), each = 2),
             to = rep(c('6mm', '4mm'), 2))
ms_edges <- do.call(rbind, list(m0, m1, m2, s0, s1))
ms_graph <- graph_from_data_frame(ms_edges)

ms_paths <- all_simple_paths(ms_graph, from = 'Start', to = c('6mm', '4mm'))

n_ms_paths <- length(ms_paths)
ms_path_colors <- viridis::cividis(n_ms_paths)

ms_g <- set_vertex_attr(make_empty_graph(directed = TRUE, n = length(V(ms_graph)$name)),
                       "name", value = V(ms_graph)$name)

ms_paths_path <- lapply(1:n_ms_paths, function(i){
  path(ms_paths[[i]], group = ((i-1) %/% 4 + 1))
})

ms_g_paths <- delete_vertices(Reduce(igraph:::`+.igraph`, c(list(ms_g), ms_paths_path)), 'Start')

#V(ms_g_paths)$name
V(ms_g_paths)$group <- unlist(mapply(rep, c('Multiverse', 'Specification'), each = c(7, 4)))

library(viridis)

ggraph(ms_g_paths,
       layout = 'igraph', algorithm = 'sugiyama') + 
  geom_edge_fan(aes(color = as.factor(group))) +
  scale_edge_color_brewer(type = 'qual', palette = 'Paired', guide = 'none') + 
  geom_node_point(size = 10,
                  aes(color = group)) +
  scale_color_manual(breaks = c('Multiverse', 'Specification'), values = viridis::mako(2, begin = .5, end = .75),
                     labels = c('Separate\nmultiverse', 'Specification\nwithin multiverse'), name = '') + 
  geom_node_text(aes(label = V(ms_g_paths)$name), repel = FALSE, colour = 'black') +
  theme_void() + 
  scale_x_continuous(expand = expansion(mult = .1)) + 
  scale_y_continuous(expand = expansion(mult = .1))
```


# Model definitions

For each measure of puberty we constructed a hierarchical linear model regressing neural activity on the pubertal measure, an indicator for ROI, and an indicator for the adjective-type contrast. We fit four models allowing these variables to interact, or not:

1. `m <- lmer( BOLD ~ puberty + ROI + contrast + (1 | id) )`
2. `m <- lmer( BOLD ~ puberty * ROI + contrast + (1 | id) )`
3. `m <- lmer( BOLD ~ puberty * contrast + ROI + (1 | id) )`
4. `m <- lmer( BOLD ~ puberty * ROI * contrast + (1 | id) )`

Importantly, the BOLD data for each model is identical, though we "stack" data from multiple ROIs and contrasts. Each model is repeated for each puberty measure.

# Criterion of interest {#sec-criterion}

The criterion of interest is, primarily, the AIC difference between best of the the 4 x 5 (pubertal measure) models and the rest. 

# Interpretation and Decision process

AIC differences &lt;10 will be considered equivolcal. Consistency of lowest AIC across analyses will be considered evidence of robustness to specifications. Additionally, we will interpret models with the lowest AIC if they are robust across specifications.

Non-robustness across Type U or Type N decisions will be discussed.

# References


